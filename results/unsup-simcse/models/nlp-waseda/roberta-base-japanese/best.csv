model_name,dataset_name,lr,batch_size,best-epoch,best-step,best-dev,jsick,jsts-val,jsts-train,avg,count
nlp-waseda/roberta-base-japanese,wikipedia,3e-05,64.0,0.0,7833.6,78.90576099440705,78.71218399030583,79.41332186318482,74.80796018431423,77.64448867926829,5
nlp-waseda/roberta-base-japanese,bccwj,5e-05,64.0,0.0,4915.2,78.52623140059205,78.44043132339189,78.71078386628936,73.73524541996358,76.96215353654827,5
nlp-waseda/roberta-base-japanese,wiki40b,5e-05,64.0,0.0,4608.0,77.54191454224777,77.47499741992249,78.95121356386915,74.08628856859438,76.83749985079534,5
nlp-waseda/roberta-base-japanese,cc100,5e-05,64.0,0.0,3584.0,73.05786488906946,73.29353970822115,77.11591735003012,72.15467045729059,74.18804250518062,5
